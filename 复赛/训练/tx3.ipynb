{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1SeZ_250grxWSnlZNbEBjc18FIgBZXC3W","authorship_tag":"ABX9TyNgo6lGeHVbmRQ+BSkgw6UR"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6WjjPtxHP8Xi","executionInfo":{"status":"ok","timestamp":1713680664776,"user_tz":-480,"elapsed":689,"user":{"displayName":"å¼ ä¹‹é¾™","userId":"09947811585758011165"}},"outputId":"4a29034c-7e4d-45ef-c43a-a01753d25817"},"outputs":[{"output_type":"stream","name":"stdout","text":["31992\n"]}],"source":["myDataset={}\n","\n","myDataset[\"dev\"]={}\n","myDataset[\"dev\"][\"ar\"]={}\n","myDataset[\"dev\"][\"ar\"][\"data\"]=[]\n","myDataset[\"dev\"][\"ar\"][\"label\"]=[]\n","myDataset[\"dev\"][\"en\"]={}\n","myDataset[\"dev\"][\"en\"][\"data\"]=[]\n","myDataset[\"dev\"][\"en\"][\"label\"]=[]\n","myDataset[\"dev\"][\"ru\"]={}\n","myDataset[\"dev\"][\"ru\"][\"data\"]=[]\n","myDataset[\"dev\"][\"ru\"][\"label\"]=[]\n","myDataset[\"dev\"][\"tr\"]={}\n","myDataset[\"dev\"][\"tr\"][\"data\"]=[]\n","myDataset[\"dev\"][\"tr\"][\"label\"]=[]\n","\n","# åˆ›å»ºè®­ç»ƒæ•°æ®é›†  ar,en,ru,trå„5k\n","myDataset[\"train1\"]={}\n","myDataset[\"train1\"][\"ar\"]={}\n","myDataset[\"train1\"][\"ar\"][\"data\"]=[]\n","myDataset[\"train1\"][\"ar\"][\"label\"]=[]\n","myDataset[\"train1\"][\"en\"]={}\n","myDataset[\"train1\"][\"en\"][\"data\"]=[]\n","myDataset[\"train1\"][\"en\"][\"label\"]=[]\n","myDataset[\"train1\"][\"ru\"]={}\n","myDataset[\"train1\"][\"ru\"][\"data\"]=[]\n","myDataset[\"train1\"][\"ru\"][\"label\"]=[]\n","myDataset[\"train1\"][\"tr\"]={}\n","myDataset[\"train1\"][\"tr\"][\"data\"]=[]\n","myDataset[\"train1\"][\"tr\"][\"label\"]=[]\n","# åˆ›å»ºè®­ç»ƒæ•°æ®é›†  ar,en,ru,trå„8k\n","myDataset[\"train2\"]={}\n","myDataset[\"train2\"][\"ar\"]={}\n","myDataset[\"train2\"][\"ar\"][\"data\"]=[]\n","myDataset[\"train2\"][\"ar\"][\"label\"]=[]\n","myDataset[\"train2\"][\"en\"]={}\n","myDataset[\"train2\"][\"en\"][\"data\"]=[]\n","myDataset[\"train2\"][\"en\"][\"label\"]=[]\n","myDataset[\"train2\"][\"ru\"]={}\n","myDataset[\"train2\"][\"ru\"][\"data\"]=[]\n","myDataset[\"train2\"][\"ru\"][\"label\"]=[]\n","myDataset[\"train2\"][\"tr\"]={}\n","myDataset[\"train2\"][\"tr\"][\"data\"]=[]\n","myDataset[\"train2\"][\"tr\"][\"label\"]=[]\n","# åŠ è½½éªŒè¯é›†æ–‡ä»¶\n","with open(\"/content/drive/MyDrive/data/dev/dev_ar.txt\",\"r\",encoding=\"utf-8\") as file:\n","  for line in file:\n","    label,data=line.split(\"|\")\n","    myDataset[\"dev\"][\"ar\"][\"data\"].append(data)\n","    myDataset[\"dev\"][\"ar\"][\"label\"].append(int(label))\n","with open(\"/content/drive/MyDrive/data/dev/dev_en.txt\",\"r\",encoding=\"utf-8\") as file:\n","  for line in file:\n","    label,data=line.split(\"|\")\n","    myDataset[\"dev\"][\"en\"][\"data\"].append(data)\n","    myDataset[\"dev\"][\"en\"][\"label\"].append(int(label))\n","with open(\"/content/drive/MyDrive/data/dev/dev_ru.txt\",\"r\",encoding=\"utf-8\") as file:\n","  for line in file:\n","    label,data=line.split(\"|\")\n","    myDataset[\"dev\"][\"ru\"][\"data\"].append(data)\n","    myDataset[\"dev\"][\"ru\"][\"label\"].append(int(label))\n","with open(\"/content/drive/MyDrive/data/dev/dev_tr.txt\",\"r\",encoding=\"utf-8\") as file:\n","  for line in file:\n","    label,data=line.split(\"|\")\n","    myDataset[\"dev\"][\"tr\"][\"data\"].append(data)\n","    myDataset[\"dev\"][\"tr\"][\"label\"].append(int(label))\n","# åŠ è½½ä½¿ç”¨chatgptæ‰“æ ‡çš„è®­ç»ƒé›†\n","with open(\"/content/drive/MyDrive/data/label_train/labeled_text_by_ChatGPT.txt\",\"r\",encoding=\"utf-8\") as file:\n","  lines=file.readlines()\n","for i in range(len(lines)):\n","  temp=lines[i].split(\"|\")\n","  myDataset[\"train1\"][f\"{temp[0]}\"][\"data\"].append(temp[1])\n","  if \"true\" in temp[2]:\n","    myDataset[\"train1\"][f\"{temp[0]}\"][\"label\"].append(1)\n","  else:\n","    myDataset[\"train1\"][f\"{temp[0]}\"][\"label\"].append(0)\n","# åŠ è½½train2è®­ç»ƒæ•°æ®é›†\n","with open(\"/content/drive/MyDrive/data/label_train/output.txt\",\"r\",encoding=\"utf-8\") as file:\n","  for line in file:\n","    myList=line.split(\"|\")\n","    if not myList:\n","      continue\n","    myDataset[\"train2\"][\"en\"][\"label\"].append(int(myList[0]))\n","    myDataset[\"train2\"][\"ar\"][\"label\"].append(int(myList[0]))\n","    myDataset[\"train2\"][\"tr\"][\"label\"].append(int(myList[0]))\n","    myDataset[\"train2\"][\"ru\"][\"label\"].append(int(myList[0]))\n","    myDataset[\"train2\"][\"en\"][\"data\"].append(myList[1])\n","    myDataset[\"train2\"][\"ar\"][\"data\"].append(myList[2])\n","    myDataset[\"train2\"][\"tr\"][\"data\"].append(myList[3])\n","    myDataset[\"train2\"][\"ru\"][\"data\"].append(myList[4])\n","myDataset[\"dev\"][\"all\"]={}\n","myDataset[\"dev\"][\"all\"][\"data\"]=myDataset[\"dev\"][\"ar\"][\"data\"]+myDataset[\"dev\"][\"en\"][\"data\"]+myDataset[\"dev\"][\"ru\"][\"data\"]+myDataset[\"dev\"][\"tr\"][\"data\"]\n","myDataset[\"dev\"][\"all\"][\"label\"]=myDataset[\"dev\"][\"ar\"][\"label\"]+myDataset[\"dev\"][\"en\"][\"label\"]+myDataset[\"dev\"][\"ru\"][\"label\"]+myDataset[\"dev\"][\"tr\"][\"label\"]\n","myDataset[\"train1\"][\"all\"]={}\n","myDataset[\"train1\"][\"all\"][\"data\"]=myDataset[\"train1\"][\"ar\"][\"data\"]+myDataset[\"train1\"][\"en\"][\"data\"]+myDataset[\"train1\"][\"ru\"][\"data\"]+myDataset[\"train1\"][\"tr\"][\"data\"]\n","myDataset[\"train1\"][\"all\"][\"label\"]=myDataset[\"train1\"][\"ar\"][\"label\"]+myDataset[\"train1\"][\"en\"][\"label\"]+myDataset[\"train1\"][\"ru\"][\"label\"]+myDataset[\"train1\"][\"tr\"][\"label\"]\n","myDataset[\"train2\"][\"all\"]={}\n","myDataset[\"train2\"][\"all\"][\"data\"]=myDataset[\"train2\"][\"ar\"][\"data\"]+myDataset[\"train2\"][\"en\"][\"data\"]+myDataset[\"train2\"][\"ru\"][\"data\"]+myDataset[\"train2\"][\"tr\"][\"data\"]\n","myDataset[\"train2\"][\"all\"][\"label\"]=myDataset[\"train2\"][\"ar\"][\"label\"]+myDataset[\"train2\"][\"en\"][\"label\"]+myDataset[\"train2\"][\"ru\"][\"label\"]+myDataset[\"train2\"][\"tr\"][\"label\"]\n","print(len(myDataset[\"train2\"][\"all\"][\"label\"]))\n","myDataset[\"train\"]={}\n","myDataset[\"train\"][\"all\"]={}\n","myDataset[\"train\"][\"all\"][\"data\"]=[]\n","myDataset[\"train\"][\"all\"][\"label\"]=[]\n","myDataset[\"train\"][\"all\"][\"data\"]=myDataset[\"train1\"][\"all\"][\"data\"]+myDataset[\"train2\"][\"all\"][\"data\"]\n","myDataset[\"train\"][\"all\"][\"label\"]=myDataset[\"train1\"][\"all\"][\"label\"]+myDataset[\"train2\"][\"all\"][\"label\"]\n"]},{"cell_type":"code","source":["# éœ€è¦å®‰è£…çš„åº“\n","!pip install --upgrade pip\n","!pip install sentencepiece\n","!pip install datasets\n","!pip install transformers\n","!pip install accelerate --upgrade\n","!pip install transformers[torch]\n","# å¯¼åŒ…\n","from transformers import AutoTokenizer,AutoModelForSequenceClassification,Trainer,TrainingArguments\n","import torch\n","import numpy as np\n","from sklearn.metrics import classification_report\n"],"metadata":{"id":"jcZ56wFZQApb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["MODEL=\"cardiffnlp/twitter-xlm-roberta-base\" #cardiffnlp/twitter-xlm-roberta-base\n","# æž„å»ºåˆ†è¯å™¨ï¼Œå¹¶ç”¨åˆ°æ•°æ®é›†é‡Œé¢\n","tokenizer=AutoTokenizer.from_pretrained(MODEL,use_fast=True)\n","dev_all=tokenizer(myDataset[\"dev\"][\"all\"][\"data\"],truncation=True,padding=True)\n","train_all=tokenizer(myDataset[\"train\"][\"all\"][\"data\"],truncation=True,padding=True)\n","import random\n","# æž„å»ºæ•°æ®é›†\n","class MyDataset(torch.utils.data.Dataset):\n","    def __init__(self, data, label):\n","        self.data = data\n","        self.label = label\n","    def __len__(self):\n","        return len(self.label)\n","    def __getitem__(self,idx):\n","        item={key :torch.tensor(value[idx]) for key,value in self.data.items()}\n","        item[\"label\"]=self.label[idx]\n","        return item\n","class RandomMyDataset(torch.utils.data.Dataset):\n","    def __init__(self, data, label,myList):\n","        self.data = data\n","        self.label = label\n","        self.numbers=myList\n","    def __len__(self):\n","        return len(self.label)\n","    def __getitem__(self,idx):\n","        idx=self.numbers[idx]\n","        item={key :torch.tensor(value[idx]) for key,value in self.data.items()}\n","        item[\"label\"]=self.label[idx]\n","        return item\n","val_dataset = MyDataset(dev_all, myDataset[\"dev\"][\"all\"][\"label\"])\n"],"metadata":{"id":"TVnFrD89QCwP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = AutoModelForSequenceClassification.from_pretrained(MODEL, num_labels=2,ignore_mismatched_sizes=True)\n","model.to(\"cuda\")\n","BATCH_SIZE_TRAIN=64\n","BATCH_SIZE_VAL=100\n","val_loader=torch.utils.data.DataLoader(val_dataset,batch_size=BATCH_SIZE_VAL)\n","EPOCHS=1\n","ALL_EPOCHS=10\n","training_args=TrainingArguments(\n","    output_dir=\"./result\",\n","    num_train_epochs=EPOCHS,\n","    per_device_train_batch_size=BATCH_SIZE_TRAIN,\n","    per_device_eval_batch_size=BATCH_SIZE_VAL,\n","    warmup_steps=100,                         # number of warmup steps for learning rate scheduler\n","    weight_decay=0.01,\n","    logging_dir='./logs',                     # directory for storing logs\n","    logging_steps=10,\n","    learning_rate=1e-5\n",")\n","\n","max_res=0\n","for _ in range(ALL_EPOCHS):\n","  import random\n","  numbers = random.sample(range(len(myDataset[\"train\"][\"all\"][\"label\"])),len(myDataset[\"train\"][\"all\"][\"label\"]) )\n","  train_dataset=RandomMyDataset(train_all,myDataset[\"train\"][\"all\"][\"label\"],numbers)\n","  # train_dataset=MyDataset(train_all,myDataset[\"train\"][\"all\"][\"label\"])\n","  #é€‰æ‹©è®­ç»ƒæ•°æ®é›†\n","  trainer = Trainer(\n","      model=model,                              # the instantiated ðŸ¤— Transformers model to be trained\n","      args=training_args,                       # training arguments, defined above\n","      train_dataset=train_dataset,              # training dataset\n","      eval_dataset=val_dataset               # evaluation dataset\n","  )\n","  trainer.train()\n","  #è¿›è¡ŒéªŒè¯é›†æµ‹è¯•å‡†ç¡®çŽ‡\n","  with torch.no_grad():\n","    precision=[]\n","    recall=[]\n","    for batch in val_loader:\n","      label=batch[\"label\"]\n","      del batch[\"label\"]\n","      batch={key:val.to(\"cuda\") for key,val in batch.items()}\n","      outputs=model(**batch)\n","      logits=outputs.logits\n","      predicted_labels=torch.argmax(logits,dim=1)\n","      report=classification_report(label,predicted_labels.cpu())\n","      print(report)\n","      lines=report.split(\"\\n\")\n","      line=lines[-2]\n","      print(line)\n","      row=line.split()\n","      precision.append(float(row[2]))\n","      recall.append(float(row[3]))\n","    res=[]\n","    with open(\"res.txt\",\"w\") as file:\n","      for i in range(4):\n","        print(f\"Precision:{precision[i]}\\nRecall:{recall[i]}\\nScore{(1+0.49)*precision[i]*recall[i]/(0.49*precision[i]+recall[i])}\")\n","        res.append((1+0.49)*precision[i]*recall[i]/(0.49*precision[i]+recall[i]))\n","        file.write(f\"Precision:{precision[i]}\\nRecall:{recall[i]}\\nScore{(1+0.49)*precision[i]*recall[i]/(0.49*precision[i]+recall[i])}\")\n","    avg_res=sum(res)/len(res)\n","    print(avg_res)\n","    if avg_res>max_res:\n","      max_res=avg_res\n","      model.save_pretrained('./bm')\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"dgr3yzGIQD8C","outputId":"8b8a3bc2-10fd-405b-e52d-d9fb9d6cba04"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at cardiffnlp/twitter-xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n","dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='813' max='813' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [813/813 21:06, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>10</td>\n","      <td>0.677100</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>0.667300</td>\n","    </tr>\n","    <tr>\n","      <td>30</td>\n","      <td>0.660600</td>\n","    </tr>\n","    <tr>\n","      <td>40</td>\n","      <td>0.657900</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>0.635200</td>\n","    </tr>\n","    <tr>\n","      <td>60</td>\n","      <td>0.639900</td>\n","    </tr>\n","    <tr>\n","      <td>70</td>\n","      <td>0.648800</td>\n","    </tr>\n","    <tr>\n","      <td>80</td>\n","      <td>0.647300</td>\n","    </tr>\n","    <tr>\n","      <td>90</td>\n","      <td>0.619200</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>0.590100</td>\n","    </tr>\n","    <tr>\n","      <td>110</td>\n","      <td>0.550400</td>\n","    </tr>\n","    <tr>\n","      <td>120</td>\n","      <td>0.535200</td>\n","    </tr>\n","    <tr>\n","      <td>130</td>\n","      <td>0.520900</td>\n","    </tr>\n","    <tr>\n","      <td>140</td>\n","      <td>0.535800</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>0.524500</td>\n","    </tr>\n","    <tr>\n","      <td>160</td>\n","      <td>0.500500</td>\n","    </tr>\n","    <tr>\n","      <td>170</td>\n","      <td>0.516600</td>\n","    </tr>\n","    <tr>\n","      <td>180</td>\n","      <td>0.469100</td>\n","    </tr>\n","    <tr>\n","      <td>190</td>\n","      <td>0.495800</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>0.521300</td>\n","    </tr>\n","    <tr>\n","      <td>210</td>\n","      <td>0.472900</td>\n","    </tr>\n","    <tr>\n","      <td>220</td>\n","      <td>0.472900</td>\n","    </tr>\n","    <tr>\n","      <td>230</td>\n","      <td>0.483200</td>\n","    </tr>\n","    <tr>\n","      <td>240</td>\n","      <td>0.476400</td>\n","    </tr>\n","    <tr>\n","      <td>250</td>\n","      <td>0.465400</td>\n","    </tr>\n","    <tr>\n","      <td>260</td>\n","      <td>0.445000</td>\n","    </tr>\n","    <tr>\n","      <td>270</td>\n","      <td>0.468800</td>\n","    </tr>\n","    <tr>\n","      <td>280</td>\n","      <td>0.448600</td>\n","    </tr>\n","    <tr>\n","      <td>290</td>\n","      <td>0.436100</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>0.455300</td>\n","    </tr>\n","    <tr>\n","      <td>310</td>\n","      <td>0.437100</td>\n","    </tr>\n","    <tr>\n","      <td>320</td>\n","      <td>0.459000</td>\n","    </tr>\n","    <tr>\n","      <td>330</td>\n","      <td>0.439500</td>\n","    </tr>\n","    <tr>\n","      <td>340</td>\n","      <td>0.450200</td>\n","    </tr>\n","    <tr>\n","      <td>350</td>\n","      <td>0.416700</td>\n","    </tr>\n","    <tr>\n","      <td>360</td>\n","      <td>0.454200</td>\n","    </tr>\n","    <tr>\n","      <td>370</td>\n","      <td>0.484500</td>\n","    </tr>\n","    <tr>\n","      <td>380</td>\n","      <td>0.431900</td>\n","    </tr>\n","    <tr>\n","      <td>390</td>\n","      <td>0.503100</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>0.406000</td>\n","    </tr>\n","    <tr>\n","      <td>410</td>\n","      <td>0.460300</td>\n","    </tr>\n","    <tr>\n","      <td>420</td>\n","      <td>0.424200</td>\n","    </tr>\n","    <tr>\n","      <td>430</td>\n","      <td>0.435000</td>\n","    </tr>\n","    <tr>\n","      <td>440</td>\n","      <td>0.440400</td>\n","    </tr>\n","    <tr>\n","      <td>450</td>\n","      <td>0.452000</td>\n","    </tr>\n","    <tr>\n","      <td>460</td>\n","      <td>0.445100</td>\n","    </tr>\n","    <tr>\n","      <td>470</td>\n","      <td>0.449000</td>\n","    </tr>\n","    <tr>\n","      <td>480</td>\n","      <td>0.450800</td>\n","    </tr>\n","    <tr>\n","      <td>490</td>\n","      <td>0.409500</td>\n","    </tr>\n","    <tr>\n","      <td>500</td>\n","      <td>0.448900</td>\n","    </tr>\n","    <tr>\n","      <td>510</td>\n","      <td>0.441100</td>\n","    </tr>\n","    <tr>\n","      <td>520</td>\n","      <td>0.417100</td>\n","    </tr>\n","    <tr>\n","      <td>530</td>\n","      <td>0.427400</td>\n","    </tr>\n","    <tr>\n","      <td>540</td>\n","      <td>0.393300</td>\n","    </tr>\n","    <tr>\n","      <td>550</td>\n","      <td>0.415200</td>\n","    </tr>\n","    <tr>\n","      <td>560</td>\n","      <td>0.420600</td>\n","    </tr>\n","    <tr>\n","      <td>570</td>\n","      <td>0.405300</td>\n","    </tr>\n","    <tr>\n","      <td>580</td>\n","      <td>0.406100</td>\n","    </tr>\n","    <tr>\n","      <td>590</td>\n","      <td>0.424200</td>\n","    </tr>\n","    <tr>\n","      <td>600</td>\n","      <td>0.448400</td>\n","    </tr>\n","    <tr>\n","      <td>610</td>\n","      <td>0.422300</td>\n","    </tr>\n","    <tr>\n","      <td>620</td>\n","      <td>0.427600</td>\n","    </tr>\n","    <tr>\n","      <td>630</td>\n","      <td>0.402800</td>\n","    </tr>\n","    <tr>\n","      <td>640</td>\n","      <td>0.413400</td>\n","    </tr>\n","    <tr>\n","      <td>650</td>\n","      <td>0.399300</td>\n","    </tr>\n","    <tr>\n","      <td>660</td>\n","      <td>0.426500</td>\n","    </tr>\n","    <tr>\n","      <td>670</td>\n","      <td>0.427800</td>\n","    </tr>\n","    <tr>\n","      <td>680</td>\n","      <td>0.449000</td>\n","    </tr>\n","    <tr>\n","      <td>690</td>\n","      <td>0.426000</td>\n","    </tr>\n","    <tr>\n","      <td>700</td>\n","      <td>0.418600</td>\n","    </tr>\n","    <tr>\n","      <td>710</td>\n","      <td>0.404900</td>\n","    </tr>\n","    <tr>\n","      <td>720</td>\n","      <td>0.428100</td>\n","    </tr>\n","    <tr>\n","      <td>730</td>\n","      <td>0.394100</td>\n","    </tr>\n","    <tr>\n","      <td>740</td>\n","      <td>0.421900</td>\n","    </tr>\n","    <tr>\n","      <td>750</td>\n","      <td>0.417100</td>\n","    </tr>\n","    <tr>\n","      <td>760</td>\n","      <td>0.411500</td>\n","    </tr>\n","    <tr>\n","      <td>770</td>\n","      <td>0.402600</td>\n","    </tr>\n","    <tr>\n","      <td>780</td>\n","      <td>0.445900</td>\n","    </tr>\n","    <tr>\n","      <td>790</td>\n","      <td>0.409400</td>\n","    </tr>\n","    <tr>\n","      <td>800</td>\n","      <td>0.425300</td>\n","    </tr>\n","    <tr>\n","      <td>810</td>\n","      <td>0.417500</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Checkpoint destination directory ./result/checkpoint-500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.57      0.96      0.71        48\n","           1       0.89      0.33      0.48        52\n","\n","    accuracy                           0.63       100\n","   macro avg       0.73      0.64      0.60       100\n","weighted avg       0.74      0.63      0.59       100\n","\n","weighted avg       0.74      0.63      0.59       100\n","              precision    recall  f1-score   support\n","\n","           0       0.80      0.89      0.84        64\n","           1       0.76      0.61      0.68        36\n","\n","    accuracy                           0.79       100\n","   macro avg       0.78      0.75      0.76       100\n","weighted avg       0.79      0.79      0.78       100\n","\n","weighted avg       0.79      0.79      0.78       100\n","              precision    recall  f1-score   support\n","\n","           0       0.37      0.76      0.50        34\n","           1       0.72      0.32      0.44        66\n","\n","    accuracy                           0.47       100\n","   macro avg       0.55      0.54      0.47       100\n","weighted avg       0.60      0.47      0.46       100\n","\n","weighted avg       0.60      0.47      0.46       100\n","              precision    recall  f1-score   support\n","\n","           0       0.66      0.97      0.78        61\n","           1       0.80      0.21      0.33        39\n","\n","    accuracy                           0.67       100\n","   macro avg       0.73      0.59      0.55       100\n","weighted avg       0.71      0.67      0.60       100\n","\n","weighted avg       0.71      0.67      0.60       100\n","Precision:0.74\n","Recall:0.63\n","Score0.6998166431593794\n","Precision:0.79\n","Recall:0.79\n","Score0.79\n","Precision:0.6\n","Recall:0.47\n","Score0.5499738219895288\n","Precision:0.71\n","Recall:0.67\n","Score0.6963287159838882\n","0.6840297952831991\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n","dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='813' max='813' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [813/813 21:04, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>10</td>\n","      <td>0.392600</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>0.411300</td>\n","    </tr>\n","    <tr>\n","      <td>30</td>\n","      <td>0.374500</td>\n","    </tr>\n","    <tr>\n","      <td>40</td>\n","      <td>0.380500</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>0.419000</td>\n","    </tr>\n","    <tr>\n","      <td>60</td>\n","      <td>0.415500</td>\n","    </tr>\n","    <tr>\n","      <td>70</td>\n","      <td>0.392000</td>\n","    </tr>\n","    <tr>\n","      <td>80</td>\n","      <td>0.376100</td>\n","    </tr>\n","    <tr>\n","      <td>90</td>\n","      <td>0.400800</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>0.414600</td>\n","    </tr>\n","    <tr>\n","      <td>110</td>\n","      <td>0.434600</td>\n","    </tr>\n","    <tr>\n","      <td>120</td>\n","      <td>0.410300</td>\n","    </tr>\n","    <tr>\n","      <td>130</td>\n","      <td>0.431700</td>\n","    </tr>\n","    <tr>\n","      <td>140</td>\n","      <td>0.371700</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>0.375700</td>\n","    </tr>\n","    <tr>\n","      <td>160</td>\n","      <td>0.439400</td>\n","    </tr>\n","    <tr>\n","      <td>170</td>\n","      <td>0.396700</td>\n","    </tr>\n","    <tr>\n","      <td>180</td>\n","      <td>0.395000</td>\n","    </tr>\n","    <tr>\n","      <td>190</td>\n","      <td>0.379400</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>0.347900</td>\n","    </tr>\n","    <tr>\n","      <td>210</td>\n","      <td>0.414700</td>\n","    </tr>\n","    <tr>\n","      <td>220</td>\n","      <td>0.379700</td>\n","    </tr>\n","    <tr>\n","      <td>230</td>\n","      <td>0.391200</td>\n","    </tr>\n","    <tr>\n","      <td>240</td>\n","      <td>0.393600</td>\n","    </tr>\n","    <tr>\n","      <td>250</td>\n","      <td>0.414700</td>\n","    </tr>\n","    <tr>\n","      <td>260</td>\n","      <td>0.402800</td>\n","    </tr>\n","    <tr>\n","      <td>270</td>\n","      <td>0.382200</td>\n","    </tr>\n","    <tr>\n","      <td>280</td>\n","      <td>0.343900</td>\n","    </tr>\n","    <tr>\n","      <td>290</td>\n","      <td>0.387300</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>0.404800</td>\n","    </tr>\n","    <tr>\n","      <td>310</td>\n","      <td>0.391400</td>\n","    </tr>\n","    <tr>\n","      <td>320</td>\n","      <td>0.362200</td>\n","    </tr>\n","    <tr>\n","      <td>330</td>\n","      <td>0.342200</td>\n","    </tr>\n","    <tr>\n","      <td>340</td>\n","      <td>0.384800</td>\n","    </tr>\n","    <tr>\n","      <td>350</td>\n","      <td>0.439200</td>\n","    </tr>\n","    <tr>\n","      <td>360</td>\n","      <td>0.382100</td>\n","    </tr>\n","    <tr>\n","      <td>370</td>\n","      <td>0.398800</td>\n","    </tr>\n","    <tr>\n","      <td>380</td>\n","      <td>0.377100</td>\n","    </tr>\n","    <tr>\n","      <td>390</td>\n","      <td>0.434900</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>0.347100</td>\n","    </tr>\n","    <tr>\n","      <td>410</td>\n","      <td>0.392400</td>\n","    </tr>\n","    <tr>\n","      <td>420</td>\n","      <td>0.390800</td>\n","    </tr>\n","    <tr>\n","      <td>430</td>\n","      <td>0.391100</td>\n","    </tr>\n","    <tr>\n","      <td>440</td>\n","      <td>0.390600</td>\n","    </tr>\n","    <tr>\n","      <td>450</td>\n","      <td>0.377200</td>\n","    </tr>\n","    <tr>\n","      <td>460</td>\n","      <td>0.407100</td>\n","    </tr>\n","    <tr>\n","      <td>470</td>\n","      <td>0.380400</td>\n","    </tr>\n","    <tr>\n","      <td>480</td>\n","      <td>0.406400</td>\n","    </tr>\n","    <tr>\n","      <td>490</td>\n","      <td>0.381000</td>\n","    </tr>\n","    <tr>\n","      <td>500</td>\n","      <td>0.381600</td>\n","    </tr>\n","    <tr>\n","      <td>510</td>\n","      <td>0.366700</td>\n","    </tr>\n","    <tr>\n","      <td>520</td>\n","      <td>0.383300</td>\n","    </tr>\n","    <tr>\n","      <td>530</td>\n","      <td>0.380700</td>\n","    </tr>\n","    <tr>\n","      <td>540</td>\n","      <td>0.398600</td>\n","    </tr>\n","    <tr>\n","      <td>550</td>\n","      <td>0.384700</td>\n","    </tr>\n","    <tr>\n","      <td>560</td>\n","      <td>0.379200</td>\n","    </tr>\n","    <tr>\n","      <td>570</td>\n","      <td>0.394100</td>\n","    </tr>\n","    <tr>\n","      <td>580</td>\n","      <td>0.358000</td>\n","    </tr>\n","    <tr>\n","      <td>590</td>\n","      <td>0.372600</td>\n","    </tr>\n","    <tr>\n","      <td>600</td>\n","      <td>0.367100</td>\n","    </tr>\n","    <tr>\n","      <td>610</td>\n","      <td>0.401800</td>\n","    </tr>\n","    <tr>\n","      <td>620</td>\n","      <td>0.386900</td>\n","    </tr>\n","    <tr>\n","      <td>630</td>\n","      <td>0.389900</td>\n","    </tr>\n","    <tr>\n","      <td>640</td>\n","      <td>0.408500</td>\n","    </tr>\n","    <tr>\n","      <td>650</td>\n","      <td>0.393000</td>\n","    </tr>\n","    <tr>\n","      <td>660</td>\n","      <td>0.354200</td>\n","    </tr>\n","    <tr>\n","      <td>670</td>\n","      <td>0.371600</td>\n","    </tr>\n","    <tr>\n","      <td>680</td>\n","      <td>0.356400</td>\n","    </tr>\n","    <tr>\n","      <td>690</td>\n","      <td>0.435400</td>\n","    </tr>\n","    <tr>\n","      <td>700</td>\n","      <td>0.362600</td>\n","    </tr>\n","    <tr>\n","      <td>710</td>\n","      <td>0.399600</td>\n","    </tr>\n","    <tr>\n","      <td>720</td>\n","      <td>0.410700</td>\n","    </tr>\n","    <tr>\n","      <td>730</td>\n","      <td>0.385700</td>\n","    </tr>\n","    <tr>\n","      <td>740</td>\n","      <td>0.350500</td>\n","    </tr>\n","    <tr>\n","      <td>750</td>\n","      <td>0.353500</td>\n","    </tr>\n","    <tr>\n","      <td>760</td>\n","      <td>0.402200</td>\n","    </tr>\n","    <tr>\n","      <td>770</td>\n","      <td>0.376000</td>\n","    </tr>\n","    <tr>\n","      <td>780</td>\n","      <td>0.388500</td>\n","    </tr>\n","    <tr>\n","      <td>790</td>\n","      <td>0.352600</td>\n","    </tr>\n","    <tr>\n","      <td>800</td>\n","      <td>0.334400</td>\n","    </tr>\n","    <tr>\n","      <td>810</td>\n","      <td>0.367400</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Checkpoint destination directory ./result/checkpoint-500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.58      0.98      0.73        48\n","           1       0.95      0.35      0.51        52\n","\n","    accuracy                           0.65       100\n","   macro avg       0.76      0.66      0.62       100\n","weighted avg       0.77      0.65      0.61       100\n","\n","weighted avg       0.77      0.65      0.61       100\n","              precision    recall  f1-score   support\n","\n","           0       0.84      0.91      0.87        64\n","           1       0.81      0.69      0.75        36\n","\n","    accuracy                           0.83       100\n","   macro avg       0.82      0.80      0.81       100\n","weighted avg       0.83      0.83      0.83       100\n","\n","weighted avg       0.83      0.83      0.83       100\n","              precision    recall  f1-score   support\n","\n","           0       0.37      0.76      0.50        34\n","           1       0.72      0.32      0.44        66\n","\n","    accuracy                           0.47       100\n","   macro avg       0.55      0.54      0.47       100\n","weighted avg       0.60      0.47      0.46       100\n","\n","weighted avg       0.60      0.47      0.46       100\n","              precision    recall  f1-score   support\n","\n","           0       0.65      0.98      0.78        61\n","           1       0.88      0.18      0.30        39\n","\n","    accuracy                           0.67       100\n","   macro avg       0.76      0.58      0.54       100\n","weighted avg       0.74      0.67      0.59       100\n","\n","weighted avg       0.74      0.67      0.59       100\n","Precision:0.77\n","Recall:0.65\n","Score0.7259271877737759\n","Precision:0.83\n","Recall:0.83\n","Score0.83\n","Precision:0.6\n","Recall:0.47\n","Score0.5499738219895288\n","Precision:0.74\n","Recall:0.67\n","Score0.7154193298469882\n","0.7053300849025732\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n","dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='813' max='813' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [813/813 21:03, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>10</td>\n","      <td>0.354100</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>0.346500</td>\n","    </tr>\n","    <tr>\n","      <td>30</td>\n","      <td>0.311100</td>\n","    </tr>\n","    <tr>\n","      <td>40</td>\n","      <td>0.303600</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>0.331800</td>\n","    </tr>\n","    <tr>\n","      <td>60</td>\n","      <td>0.324300</td>\n","    </tr>\n","    <tr>\n","      <td>70</td>\n","      <td>0.263400</td>\n","    </tr>\n","    <tr>\n","      <td>80</td>\n","      <td>0.255000</td>\n","    </tr>\n","    <tr>\n","      <td>90</td>\n","      <td>0.261700</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>0.283300</td>\n","    </tr>\n","    <tr>\n","      <td>110</td>\n","      <td>0.280000</td>\n","    </tr>\n","    <tr>\n","      <td>120</td>\n","      <td>0.248200</td>\n","    </tr>\n","    <tr>\n","      <td>130</td>\n","      <td>0.289300</td>\n","    </tr>\n","    <tr>\n","      <td>140</td>\n","      <td>0.226400</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>0.234900</td>\n","    </tr>\n","    <tr>\n","      <td>160</td>\n","      <td>0.301600</td>\n","    </tr>\n","    <tr>\n","      <td>170</td>\n","      <td>0.264100</td>\n","    </tr>\n","    <tr>\n","      <td>180</td>\n","      <td>0.248500</td>\n","    </tr>\n","    <tr>\n","      <td>190</td>\n","      <td>0.246500</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>0.206600</td>\n","    </tr>\n","    <tr>\n","      <td>210</td>\n","      <td>0.261100</td>\n","    </tr>\n","    <tr>\n","      <td>220</td>\n","      <td>0.230300</td>\n","    </tr>\n","    <tr>\n","      <td>230</td>\n","      <td>0.252000</td>\n","    </tr>\n","    <tr>\n","      <td>240</td>\n","      <td>0.266900</td>\n","    </tr>\n","    <tr>\n","      <td>250</td>\n","      <td>0.270900</td>\n","    </tr>\n","    <tr>\n","      <td>260</td>\n","      <td>0.262200</td>\n","    </tr>\n","    <tr>\n","      <td>270</td>\n","      <td>0.252000</td>\n","    </tr>\n","    <tr>\n","      <td>280</td>\n","      <td>0.203800</td>\n","    </tr>\n","    <tr>\n","      <td>290</td>\n","      <td>0.244100</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>0.283700</td>\n","    </tr>\n","    <tr>\n","      <td>310</td>\n","      <td>0.268600</td>\n","    </tr>\n","    <tr>\n","      <td>320</td>\n","      <td>0.252800</td>\n","    </tr>\n","    <tr>\n","      <td>330</td>\n","      <td>0.223100</td>\n","    </tr>\n","    <tr>\n","      <td>340</td>\n","      <td>0.244500</td>\n","    </tr>\n","    <tr>\n","      <td>350</td>\n","      <td>0.349200</td>\n","    </tr>\n","    <tr>\n","      <td>360</td>\n","      <td>0.280800</td>\n","    </tr>\n","    <tr>\n","      <td>370</td>\n","      <td>0.286400</td>\n","    </tr>\n","    <tr>\n","      <td>380</td>\n","      <td>0.277900</td>\n","    </tr>\n","    <tr>\n","      <td>390</td>\n","      <td>0.339300</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>0.239900</td>\n","    </tr>\n","    <tr>\n","      <td>410</td>\n","      <td>0.271200</td>\n","    </tr>\n","    <tr>\n","      <td>420</td>\n","      <td>0.297900</td>\n","    </tr>\n","    <tr>\n","      <td>430</td>\n","      <td>0.285200</td>\n","    </tr>\n","    <tr>\n","      <td>440</td>\n","      <td>0.288200</td>\n","    </tr>\n","    <tr>\n","      <td>450</td>\n","      <td>0.285500</td>\n","    </tr>\n","    <tr>\n","      <td>460</td>\n","      <td>0.322100</td>\n","    </tr>\n","    <tr>\n","      <td>470</td>\n","      <td>0.290600</td>\n","    </tr>\n","    <tr>\n","      <td>480</td>\n","      <td>0.329800</td>\n","    </tr>\n","    <tr>\n","      <td>490</td>\n","      <td>0.298500</td>\n","    </tr>\n","    <tr>\n","      <td>500</td>\n","      <td>0.298200</td>\n","    </tr>\n","    <tr>\n","      <td>510</td>\n","      <td>0.286600</td>\n","    </tr>\n","    <tr>\n","      <td>520</td>\n","      <td>0.306800</td>\n","    </tr>\n","    <tr>\n","      <td>530</td>\n","      <td>0.311600</td>\n","    </tr>\n","    <tr>\n","      <td>540</td>\n","      <td>0.314500</td>\n","    </tr>\n","    <tr>\n","      <td>550</td>\n","      <td>0.324400</td>\n","    </tr>\n","    <tr>\n","      <td>560</td>\n","      <td>0.312100</td>\n","    </tr>\n","    <tr>\n","      <td>570</td>\n","      <td>0.330400</td>\n","    </tr>\n","    <tr>\n","      <td>580</td>\n","      <td>0.289500</td>\n","    </tr>\n","    <tr>\n","      <td>590</td>\n","      <td>0.305700</td>\n","    </tr>\n","    <tr>\n","      <td>600</td>\n","      <td>0.298000</td>\n","    </tr>\n","    <tr>\n","      <td>610</td>\n","      <td>0.347700</td>\n","    </tr>\n","    <tr>\n","      <td>620</td>\n","      <td>0.329900</td>\n","    </tr>\n","    <tr>\n","      <td>630</td>\n","      <td>0.349700</td>\n","    </tr>\n","    <tr>\n","      <td>640</td>\n","      <td>0.356200</td>\n","    </tr>\n","    <tr>\n","      <td>650</td>\n","      <td>0.345500</td>\n","    </tr>\n","    <tr>\n","      <td>660</td>\n","      <td>0.300800</td>\n","    </tr>\n","    <tr>\n","      <td>670</td>\n","      <td>0.337500</td>\n","    </tr>\n","    <tr>\n","      <td>680</td>\n","      <td>0.317900</td>\n","    </tr>\n","    <tr>\n","      <td>690</td>\n","      <td>0.392000</td>\n","    </tr>\n","    <tr>\n","      <td>700</td>\n","      <td>0.330500</td>\n","    </tr>\n","    <tr>\n","      <td>710</td>\n","      <td>0.365900</td>\n","    </tr>\n","    <tr>\n","      <td>720</td>\n","      <td>0.383600</td>\n","    </tr>\n","    <tr>\n","      <td>730</td>\n","      <td>0.346100</td>\n","    </tr>\n","    <tr>\n","      <td>740</td>\n","      <td>0.318700</td>\n","    </tr>\n","    <tr>\n","      <td>750</td>\n","      <td>0.329400</td>\n","    </tr>\n","    <tr>\n","      <td>760</td>\n","      <td>0.391200</td>\n","    </tr>\n","    <tr>\n","      <td>770</td>\n","      <td>0.367000</td>\n","    </tr>\n","    <tr>\n","      <td>780</td>\n","      <td>0.380800</td>\n","    </tr>\n","    <tr>\n","      <td>790</td>\n","      <td>0.335300</td>\n","    </tr>\n","    <tr>\n","      <td>800</td>\n","      <td>0.333600</td>\n","    </tr>\n","    <tr>\n","      <td>810</td>\n","      <td>0.371300</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Checkpoint destination directory ./result/checkpoint-500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.60      0.98      0.75        48\n","           1       0.95      0.40      0.57        52\n","\n","    accuracy                           0.68       100\n","   macro avg       0.78      0.69      0.66       100\n","weighted avg       0.79      0.68      0.65       100\n","\n","weighted avg       0.79      0.68      0.65       100\n","              precision    recall  f1-score   support\n","\n","           0       0.83      0.94      0.88        64\n","           1       0.86      0.67      0.75        36\n","\n","    accuracy                           0.84       100\n","   macro avg       0.85      0.80      0.82       100\n","weighted avg       0.84      0.84      0.83       100\n","\n","weighted avg       0.84      0.84      0.83       100\n","              precision    recall  f1-score   support\n","\n","           0       0.39      0.79      0.52        34\n","           1       0.77      0.35      0.48        66\n","\n","    accuracy                           0.50       100\n","   macro avg       0.58      0.57      0.50       100\n","weighted avg       0.64      0.50      0.49       100\n","\n","weighted avg       0.64      0.50      0.49       100\n","              precision    recall  f1-score   support\n","\n","           0       0.65      0.97      0.78        61\n","           1       0.78      0.18      0.29        39\n","\n","    accuracy                           0.66       100\n","   macro avg       0.71      0.57      0.53       100\n","weighted avg       0.70      0.66      0.59       100\n","\n","weighted avg       0.70      0.66      0.59       100\n","Precision:0.79\n","Recall:0.68\n","Score0.7500965232874146\n","Precision:0.84\n","Recall:0.84\n","Score0.8400000000000002\n","Precision:0.64\n","Recall:0.5\n","Score0.5860373647984267\n","Precision:0.7\n","Recall:0.66\n","Score0.6863210368893319\n","0.7156137312437933\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n","dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='813' max='813' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [813/813 21:07, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>10</td>\n","      <td>0.314000</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>0.294400</td>\n","    </tr>\n","    <tr>\n","      <td>30</td>\n","      <td>0.241000</td>\n","    </tr>\n","    <tr>\n","      <td>40</td>\n","      <td>0.224600</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>0.230700</td>\n","    </tr>\n","    <tr>\n","      <td>60</td>\n","      <td>0.215100</td>\n","    </tr>\n","    <tr>\n","      <td>70</td>\n","      <td>0.150700</td>\n","    </tr>\n","    <tr>\n","      <td>80</td>\n","      <td>0.132000</td>\n","    </tr>\n","    <tr>\n","      <td>90</td>\n","      <td>0.131100</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>0.158800</td>\n","    </tr>\n","    <tr>\n","      <td>110</td>\n","      <td>0.142100</td>\n","    </tr>\n","    <tr>\n","      <td>120</td>\n","      <td>0.096900</td>\n","    </tr>\n","    <tr>\n","      <td>130</td>\n","      <td>0.147800</td>\n","    </tr>\n","    <tr>\n","      <td>140</td>\n","      <td>0.114600</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>0.120800</td>\n","    </tr>\n","    <tr>\n","      <td>160</td>\n","      <td>0.157900</td>\n","    </tr>\n","    <tr>\n","      <td>170</td>\n","      <td>0.144800</td>\n","    </tr>\n","    <tr>\n","      <td>180</td>\n","      <td>0.112000</td>\n","    </tr>\n","    <tr>\n","      <td>190</td>\n","      <td>0.097100</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>0.075500</td>\n","    </tr>\n","    <tr>\n","      <td>210</td>\n","      <td>0.118200</td>\n","    </tr>\n","    <tr>\n","      <td>220</td>\n","      <td>0.088200</td>\n","    </tr>\n","    <tr>\n","      <td>230</td>\n","      <td>0.116000</td>\n","    </tr>\n","    <tr>\n","      <td>240</td>\n","      <td>0.135900</td>\n","    </tr>\n","    <tr>\n","      <td>250</td>\n","      <td>0.123500</td>\n","    </tr>\n","    <tr>\n","      <td>260</td>\n","      <td>0.125900</td>\n","    </tr>\n","    <tr>\n","      <td>270</td>\n","      <td>0.111900</td>\n","    </tr>\n","    <tr>\n","      <td>280</td>\n","      <td>0.106600</td>\n","    </tr>\n","    <tr>\n","      <td>290</td>\n","      <td>0.117700</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>0.172400</td>\n","    </tr>\n","    <tr>\n","      <td>310</td>\n","      <td>0.150500</td>\n","    </tr>\n","    <tr>\n","      <td>320</td>\n","      <td>0.120800</td>\n","    </tr>\n","    <tr>\n","      <td>330</td>\n","      <td>0.112700</td>\n","    </tr>\n","    <tr>\n","      <td>340</td>\n","      <td>0.121600</td>\n","    </tr>\n","    <tr>\n","      <td>350</td>\n","      <td>0.225900</td>\n","    </tr>\n","    <tr>\n","      <td>360</td>\n","      <td>0.161000</td>\n","    </tr>\n","    <tr>\n","      <td>370</td>\n","      <td>0.179900</td>\n","    </tr>\n","    <tr>\n","      <td>380</td>\n","      <td>0.140900</td>\n","    </tr>\n","    <tr>\n","      <td>390</td>\n","      <td>0.230500</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>0.123500</td>\n","    </tr>\n","    <tr>\n","      <td>410</td>\n","      <td>0.144500</td>\n","    </tr>\n","    <tr>\n","      <td>420</td>\n","      <td>0.192300</td>\n","    </tr>\n","    <tr>\n","      <td>430</td>\n","      <td>0.167800</td>\n","    </tr>\n","    <tr>\n","      <td>440</td>\n","      <td>0.158800</td>\n","    </tr>\n","    <tr>\n","      <td>450</td>\n","      <td>0.193300</td>\n","    </tr>\n","    <tr>\n","      <td>460</td>\n","      <td>0.218200</td>\n","    </tr>\n","    <tr>\n","      <td>470</td>\n","      <td>0.184900</td>\n","    </tr>\n","    <tr>\n","      <td>480</td>\n","      <td>0.227600</td>\n","    </tr>\n","    <tr>\n","      <td>490</td>\n","      <td>0.202000</td>\n","    </tr>\n","    <tr>\n","      <td>500</td>\n","      <td>0.194200</td>\n","    </tr>\n","    <tr>\n","      <td>510</td>\n","      <td>0.197700</td>\n","    </tr>\n","    <tr>\n","      <td>520</td>\n","      <td>0.222600</td>\n","    </tr>\n","    <tr>\n","      <td>530</td>\n","      <td>0.224400</td>\n","    </tr>\n","    <tr>\n","      <td>540</td>\n","      <td>0.228600</td>\n","    </tr>\n","    <tr>\n","      <td>550</td>\n","      <td>0.253500</td>\n","    </tr>\n","    <tr>\n","      <td>560</td>\n","      <td>0.224900</td>\n","    </tr>\n","    <tr>\n","      <td>570</td>\n","      <td>0.264600</td>\n","    </tr>\n","    <tr>\n","      <td>580</td>\n","      <td>0.226500</td>\n","    </tr>\n","    <tr>\n","      <td>590</td>\n","      <td>0.231900</td>\n","    </tr>\n","    <tr>\n","      <td>600</td>\n","      <td>0.227000</td>\n","    </tr>\n","    <tr>\n","      <td>610</td>\n","      <td>0.290600</td>\n","    </tr>\n","    <tr>\n","      <td>620</td>\n","      <td>0.273800</td>\n","    </tr>\n","    <tr>\n","      <td>630</td>\n","      <td>0.307100</td>\n","    </tr>\n","    <tr>\n","      <td>640</td>\n","      <td>0.297800</td>\n","    </tr>\n","    <tr>\n","      <td>650</td>\n","      <td>0.305300</td>\n","    </tr>\n","    <tr>\n","      <td>660</td>\n","      <td>0.251300</td>\n","    </tr>\n","    <tr>\n","      <td>670</td>\n","      <td>0.299700</td>\n","    </tr>\n","    <tr>\n","      <td>680</td>\n","      <td>0.276900</td>\n","    </tr>\n","    <tr>\n","      <td>690</td>\n","      <td>0.349100</td>\n","    </tr>\n","    <tr>\n","      <td>700</td>\n","      <td>0.294600</td>\n","    </tr>\n","    <tr>\n","      <td>710</td>\n","      <td>0.340800</td>\n","    </tr>\n","    <tr>\n","      <td>720</td>\n","      <td>0.357900</td>\n","    </tr>\n","    <tr>\n","      <td>730</td>\n","      <td>0.317500</td>\n","    </tr>\n","    <tr>\n","      <td>740</td>\n","      <td>0.298400</td>\n","    </tr>\n","    <tr>\n","      <td>750</td>\n","      <td>0.316100</td>\n","    </tr>\n","    <tr>\n","      <td>760</td>\n","      <td>0.387200</td>\n","    </tr>\n","    <tr>\n","      <td>770</td>\n","      <td>0.380200</td>\n","    </tr>\n","    <tr>\n","      <td>780</td>\n","      <td>0.389800</td>\n","    </tr>\n","    <tr>\n","      <td>790</td>\n","      <td>0.343600</td>\n","    </tr>\n","    <tr>\n","      <td>800</td>\n","      <td>0.351000</td>\n","    </tr>\n","    <tr>\n","      <td>810</td>\n","      <td>0.401300</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Checkpoint destination directory ./result/checkpoint-500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.61      0.96      0.75        48\n","           1       0.92      0.44      0.60        52\n","\n","    accuracy                           0.69       100\n","   macro avg       0.77      0.70      0.67       100\n","weighted avg       0.77      0.69      0.67       100\n","\n","weighted avg       0.77      0.69      0.67       100\n","              precision    recall  f1-score   support\n","\n","           0       0.83      0.89      0.86        64\n","           1       0.77      0.67      0.72        36\n","\n","    accuracy                           0.81       100\n","   macro avg       0.80      0.78      0.79       100\n","weighted avg       0.81      0.81      0.81       100\n","\n","weighted avg       0.81      0.81      0.81       100\n","              precision    recall  f1-score   support\n","\n","           0       0.40      0.79      0.53        34\n","           1       0.78      0.38      0.51        66\n","\n","    accuracy                           0.52       100\n","   macro avg       0.59      0.59      0.52       100\n","weighted avg       0.65      0.52      0.52       100\n","\n","weighted avg       0.65      0.52      0.52       100\n","              precision    recall  f1-score   support\n","\n","           0       0.65      0.95      0.77        61\n","           1       0.73      0.21      0.32        39\n","\n","    accuracy                           0.66       100\n","   macro avg       0.69      0.58      0.55       100\n","weighted avg       0.68      0.66      0.60       100\n","\n","weighted avg       0.68      0.66      0.60       100\n","Precision:0.77\n","Recall:0.69\n","Score0.7417192916705706\n","Precision:0.81\n","Recall:0.81\n","Score0.81\n","Precision:0.65\n","Recall:0.52\n","Score0.6006201550387598\n","Precision:0.68\n","Recall:0.66\n","Score0.6732903745469191\n","0.7064074553140623\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n","dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='813' max='813' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [813/813 21:15, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>10</td>\n","      <td>0.274900</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>0.240600</td>\n","    </tr>\n","    <tr>\n","      <td>30</td>\n","      <td>0.168800</td>\n","    </tr>\n","    <tr>\n","      <td>40</td>\n","      <td>0.144600</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>0.135300</td>\n","    </tr>\n","    <tr>\n","      <td>60</td>\n","      <td>0.115200</td>\n","    </tr>\n","    <tr>\n","      <td>70</td>\n","      <td>0.068700</td>\n","    </tr>\n","    <tr>\n","      <td>80</td>\n","      <td>0.045700</td>\n","    </tr>\n","    <tr>\n","      <td>90</td>\n","      <td>0.043800</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>0.055800</td>\n","    </tr>\n","    <tr>\n","      <td>110</td>\n","      <td>0.050100</td>\n","    </tr>\n","    <tr>\n","      <td>120</td>\n","      <td>0.023700</td>\n","    </tr>\n","    <tr>\n","      <td>130</td>\n","      <td>0.053700</td>\n","    </tr>\n","    <tr>\n","      <td>140</td>\n","      <td>0.049800</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>0.042800</td>\n","    </tr>\n","    <tr>\n","      <td>160</td>\n","      <td>0.065600</td>\n","    </tr>\n","    <tr>\n","      <td>170</td>\n","      <td>0.061500</td>\n","    </tr>\n","    <tr>\n","      <td>180</td>\n","      <td>0.027000</td>\n","    </tr>\n","    <tr>\n","      <td>190</td>\n","      <td>0.018900</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>0.023800</td>\n","    </tr>\n","    <tr>\n","      <td>210</td>\n","      <td>0.057600</td>\n","    </tr>\n","    <tr>\n","      <td>220</td>\n","      <td>0.021000</td>\n","    </tr>\n","    <tr>\n","      <td>230</td>\n","      <td>0.038400</td>\n","    </tr>\n","    <tr>\n","      <td>240</td>\n","      <td>0.048400</td>\n","    </tr>\n","    <tr>\n","      <td>250</td>\n","      <td>0.040800</td>\n","    </tr>\n","    <tr>\n","      <td>260</td>\n","      <td>0.059200</td>\n","    </tr>\n","    <tr>\n","      <td>270</td>\n","      <td>0.049100</td>\n","    </tr>\n","    <tr>\n","      <td>280</td>\n","      <td>0.066000</td>\n","    </tr>\n","    <tr>\n","      <td>290</td>\n","      <td>0.045900</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>0.089500</td>\n","    </tr>\n","    <tr>\n","      <td>310</td>\n","      <td>0.059900</td>\n","    </tr>\n","    <tr>\n","      <td>320</td>\n","      <td>0.040000</td>\n","    </tr>\n","    <tr>\n","      <td>330</td>\n","      <td>0.039600</td>\n","    </tr>\n","    <tr>\n","      <td>340</td>\n","      <td>0.026100</td>\n","    </tr>\n","    <tr>\n","      <td>350</td>\n","      <td>0.137700</td>\n","    </tr>\n","    <tr>\n","      <td>360</td>\n","      <td>0.069200</td>\n","    </tr>\n","    <tr>\n","      <td>370</td>\n","      <td>0.086500</td>\n","    </tr>\n","    <tr>\n","      <td>380</td>\n","      <td>0.043800</td>\n","    </tr>\n","    <tr>\n","      <td>390</td>\n","      <td>0.133400</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>0.031200</td>\n","    </tr>\n","    <tr>\n","      <td>410</td>\n","      <td>0.047200</td>\n","    </tr>\n","    <tr>\n","      <td>420</td>\n","      <td>0.086700</td>\n","    </tr>\n","    <tr>\n","      <td>430</td>\n","      <td>0.089100</td>\n","    </tr>\n","    <tr>\n","      <td>440</td>\n","      <td>0.084200</td>\n","    </tr>\n","    <tr>\n","      <td>450</td>\n","      <td>0.120900</td>\n","    </tr>\n","    <tr>\n","      <td>460</td>\n","      <td>0.112100</td>\n","    </tr>\n","    <tr>\n","      <td>470</td>\n","      <td>0.091400</td>\n","    </tr>\n","    <tr>\n","      <td>480</td>\n","      <td>0.131500</td>\n","    </tr>\n","    <tr>\n","      <td>490</td>\n","      <td>0.134500</td>\n","    </tr>\n","    <tr>\n","      <td>500</td>\n","      <td>0.109100</td>\n","    </tr>\n","    <tr>\n","      <td>510</td>\n","      <td>0.116700</td>\n","    </tr>\n","    <tr>\n","      <td>520</td>\n","      <td>0.122000</td>\n","    </tr>\n","    <tr>\n","      <td>530</td>\n","      <td>0.131000</td>\n","    </tr>\n","    <tr>\n","      <td>540</td>\n","      <td>0.143100</td>\n","    </tr>\n","    <tr>\n","      <td>550</td>\n","      <td>0.165300</td>\n","    </tr>\n","    <tr>\n","      <td>560</td>\n","      <td>0.154500</td>\n","    </tr>\n","    <tr>\n","      <td>570</td>\n","      <td>0.186400</td>\n","    </tr>\n","    <tr>\n","      <td>580</td>\n","      <td>0.162900</td>\n","    </tr>\n","    <tr>\n","      <td>590</td>\n","      <td>0.149600</td>\n","    </tr>\n","    <tr>\n","      <td>600</td>\n","      <td>0.153900</td>\n","    </tr>\n","    <tr>\n","      <td>610</td>\n","      <td>0.215500</td>\n","    </tr>\n","    <tr>\n","      <td>620</td>\n","      <td>0.221000</td>\n","    </tr>\n","    <tr>\n","      <td>630</td>\n","      <td>0.249800</td>\n","    </tr>\n","    <tr>\n","      <td>640</td>\n","      <td>0.244600</td>\n","    </tr>\n","    <tr>\n","      <td>650</td>\n","      <td>0.249900</td>\n","    </tr>\n","    <tr>\n","      <td>660</td>\n","      <td>0.198300</td>\n","    </tr>\n","    <tr>\n","      <td>670</td>\n","      <td>0.267000</td>\n","    </tr>\n","    <tr>\n","      <td>680</td>\n","      <td>0.232300</td>\n","    </tr>\n","    <tr>\n","      <td>690</td>\n","      <td>0.313900</td>\n","    </tr>\n","    <tr>\n","      <td>700</td>\n","      <td>0.242600</td>\n","    </tr>\n","    <tr>\n","      <td>710</td>\n","      <td>0.330900</td>\n","    </tr>\n","    <tr>\n","      <td>720</td>\n","      <td>0.350500</td>\n","    </tr>\n","    <tr>\n","      <td>730</td>\n","      <td>0.297000</td>\n","    </tr>\n","    <tr>\n","      <td>740</td>\n","      <td>0.298900</td>\n","    </tr>\n","    <tr>\n","      <td>750</td>\n","      <td>0.292200</td>\n","    </tr>\n","    <tr>\n","      <td>760</td>\n","      <td>0.396800</td>\n","    </tr>\n","    <tr>\n","      <td>770</td>\n","      <td>0.421400</td>\n","    </tr>\n","    <tr>\n","      <td>780</td>\n","      <td>0.435500</td>\n","    </tr>\n","    <tr>\n","      <td>790</td>\n","      <td>0.377700</td>\n","    </tr>\n","    <tr>\n","      <td>800</td>\n","      <td>0.397200</td>\n","    </tr>\n","    <tr>\n","      <td>810</td>\n","      <td>0.473800</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Checkpoint destination directory ./result/checkpoint-500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.59      0.92      0.72        48\n","           1       0.85      0.42      0.56        52\n","\n","    accuracy                           0.66       100\n","   macro avg       0.72      0.67      0.64       100\n","weighted avg       0.73      0.66      0.64       100\n","\n","weighted avg       0.73      0.66      0.64       100\n","              precision    recall  f1-score   support\n","\n","           0       0.83      0.91      0.87        64\n","           1       0.80      0.67      0.73        36\n","\n","    accuracy                           0.82       100\n","   macro avg       0.81      0.79      0.80       100\n","weighted avg       0.82      0.82      0.82       100\n","\n","weighted avg       0.82      0.82      0.82       100\n","              precision    recall  f1-score   support\n","\n","           0       0.38      0.79      0.51        34\n","           1       0.76      0.33      0.46        66\n","\n","    accuracy                           0.49       100\n","   macro avg       0.57      0.56      0.49       100\n","weighted avg       0.63      0.49      0.48       100\n","\n","weighted avg       0.63      0.49      0.48       100\n","              precision    recall  f1-score   support\n","\n","           0       0.66      0.95      0.78        61\n","           1       0.75      0.23      0.35        39\n","\n","    accuracy                           0.67       100\n","   macro avg       0.70      0.59      0.57       100\n","weighted avg       0.69      0.67      0.61       100\n","\n","weighted avg       0.69      0.67      0.61       100\n","Precision:0.73\n","Recall:0.66\n","Score0.7053964822639284\n","Precision:0.82\n","Recall:0.82\n","Score0.82\n","Precision:0.63\n","Recall:0.49\n","Score0.5758895705521472\n","Precision:0.69\n","Recall:0.67\n","Score0.6832923321099098\n","0.6961445962314963\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n","dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='813' max='813' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [813/813 21:05, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>10</td>\n","      <td>0.243700</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>0.179500</td>\n","    </tr>\n","    <tr>\n","      <td>30</td>\n","      <td>0.100700</td>\n","    </tr>\n","    <tr>\n","      <td>40</td>\n","      <td>0.074100</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>0.057300</td>\n","    </tr>\n","    <tr>\n","      <td>60</td>\n","      <td>0.033300</td>\n","    </tr>\n","    <tr>\n","      <td>70</td>\n","      <td>0.009600</td>\n","    </tr>\n","    <tr>\n","      <td>80</td>\n","      <td>0.015100</td>\n","    </tr>\n","    <tr>\n","      <td>90</td>\n","      <td>0.008700</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>0.014600</td>\n","    </tr>\n","    <tr>\n","      <td>110</td>\n","      <td>0.005600</td>\n","    </tr>\n","    <tr>\n","      <td>120</td>\n","      <td>0.012100</td>\n","    </tr>\n","    <tr>\n","      <td>130</td>\n","      <td>0.016100</td>\n","    </tr>\n","    <tr>\n","      <td>140</td>\n","      <td>0.007900</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>0.009600</td>\n","    </tr>\n","    <tr>\n","      <td>160</td>\n","      <td>0.035000</td>\n","    </tr>\n","    <tr>\n","      <td>170</td>\n","      <td>0.015400</td>\n","    </tr>\n","    <tr>\n","      <td>180</td>\n","      <td>0.005700</td>\n","    </tr>\n","    <tr>\n","      <td>190</td>\n","      <td>0.001400</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>0.005400</td>\n","    </tr>\n","    <tr>\n","      <td>210</td>\n","      <td>0.013400</td>\n","    </tr>\n","    <tr>\n","      <td>220</td>\n","      <td>0.010700</td>\n","    </tr>\n","    <tr>\n","      <td>230</td>\n","      <td>0.008700</td>\n","    </tr>\n","    <tr>\n","      <td>240</td>\n","      <td>0.027900</td>\n","    </tr>\n","    <tr>\n","      <td>250</td>\n","      <td>0.031100</td>\n","    </tr>\n","    <tr>\n","      <td>260</td>\n","      <td>0.040100</td>\n","    </tr>\n","    <tr>\n","      <td>270</td>\n","      <td>0.009600</td>\n","    </tr>\n","    <tr>\n","      <td>280</td>\n","      <td>0.029200</td>\n","    </tr>\n","    <tr>\n","      <td>290</td>\n","      <td>0.022400</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>0.048800</td>\n","    </tr>\n","    <tr>\n","      <td>310</td>\n","      <td>0.031500</td>\n","    </tr>\n","    <tr>\n","      <td>320</td>\n","      <td>0.005300</td>\n","    </tr>\n","    <tr>\n","      <td>330</td>\n","      <td>0.007700</td>\n","    </tr>\n","    <tr>\n","      <td>340</td>\n","      <td>0.006800</td>\n","    </tr>\n","    <tr>\n","      <td>350</td>\n","      <td>0.074700</td>\n","    </tr>\n","    <tr>\n","      <td>360</td>\n","      <td>0.019600</td>\n","    </tr>\n","    <tr>\n","      <td>370</td>\n","      <td>0.039400</td>\n","    </tr>\n","    <tr>\n","      <td>380</td>\n","      <td>0.007700</td>\n","    </tr>\n","    <tr>\n","      <td>390</td>\n","      <td>0.031700</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>0.004800</td>\n","    </tr>\n","    <tr>\n","      <td>410</td>\n","      <td>0.008600</td>\n","    </tr>\n","    <tr>\n","      <td>420</td>\n","      <td>0.035800</td>\n","    </tr>\n","    <tr>\n","      <td>430</td>\n","      <td>0.038200</td>\n","    </tr>\n","    <tr>\n","      <td>440</td>\n","      <td>0.046800</td>\n","    </tr>\n","    <tr>\n","      <td>450</td>\n","      <td>0.073400</td>\n","    </tr>\n","    <tr>\n","      <td>460</td>\n","      <td>0.045100</td>\n","    </tr>\n","    <tr>\n","      <td>470</td>\n","      <td>0.052300</td>\n","    </tr>\n","    <tr>\n","      <td>480</td>\n","      <td>0.075300</td>\n","    </tr>\n","    <tr>\n","      <td>490</td>\n","      <td>0.063700</td>\n","    </tr>\n","    <tr>\n","      <td>500</td>\n","      <td>0.051500</td>\n","    </tr>\n","    <tr>\n","      <td>510</td>\n","      <td>0.051700</td>\n","    </tr>\n","    <tr>\n","      <td>520</td>\n","      <td>0.075500</td>\n","    </tr>\n","    <tr>\n","      <td>530</td>\n","      <td>0.075200</td>\n","    </tr>\n","    <tr>\n","      <td>540</td>\n","      <td>0.072800</td>\n","    </tr>\n","    <tr>\n","      <td>550</td>\n","      <td>0.084500</td>\n","    </tr>\n","    <tr>\n","      <td>560</td>\n","      <td>0.103900</td>\n","    </tr>\n","    <tr>\n","      <td>570</td>\n","      <td>0.119000</td>\n","    </tr>\n","    <tr>\n","      <td>580</td>\n","      <td>0.109200</td>\n","    </tr>\n","    <tr>\n","      <td>590</td>\n","      <td>0.087200</td>\n","    </tr>\n","    <tr>\n","      <td>600</td>\n","      <td>0.090400</td>\n","    </tr>\n","    <tr>\n","      <td>610</td>\n","      <td>0.143500</td>\n","    </tr>\n","    <tr>\n","      <td>620</td>\n","      <td>0.151900</td>\n","    </tr>\n","    <tr>\n","      <td>630</td>\n","      <td>0.190600</td>\n","    </tr>\n","    <tr>\n","      <td>640</td>\n","      <td>0.207800</td>\n","    </tr>\n","    <tr>\n","      <td>650</td>\n","      <td>0.178900</td>\n","    </tr>\n","    <tr>\n","      <td>660</td>\n","      <td>0.148200</td>\n","    </tr>\n","    <tr>\n","      <td>670</td>\n","      <td>0.236900</td>\n","    </tr>\n","    <tr>\n","      <td>680</td>\n","      <td>0.205600</td>\n","    </tr>\n","    <tr>\n","      <td>690</td>\n","      <td>0.279100</td>\n","    </tr>\n","    <tr>\n","      <td>700</td>\n","      <td>0.199700</td>\n","    </tr>\n","    <tr>\n","      <td>710</td>\n","      <td>0.310900</td>\n","    </tr>\n","    <tr>\n","      <td>720</td>\n","      <td>0.349100</td>\n","    </tr>\n","    <tr>\n","      <td>730</td>\n","      <td>0.286800</td>\n","    </tr>\n","    <tr>\n","      <td>740</td>\n","      <td>0.304000</td>\n","    </tr>\n","    <tr>\n","      <td>750</td>\n","      <td>0.290900</td>\n","    </tr>\n","    <tr>\n","      <td>760</td>\n","      <td>0.423800</td>\n","    </tr>\n","    <tr>\n","      <td>770</td>\n","      <td>0.458700</td>\n","    </tr>\n","    <tr>\n","      <td>780</td>\n","      <td>0.500800</td>\n","    </tr>\n","    <tr>\n","      <td>790</td>\n","      <td>0.429400</td>\n","    </tr>\n","    <tr>\n","      <td>800</td>\n","      <td>0.490800</td>\n","    </tr>\n","    <tr>\n","      <td>810</td>\n","      <td>0.577200</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Checkpoint destination directory ./result/checkpoint-500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.60      0.94      0.73        48\n","           1       0.88      0.42      0.57        52\n","\n","    accuracy                           0.67       100\n","   macro avg       0.74      0.68      0.65       100\n","weighted avg       0.75      0.67      0.65       100\n","\n","weighted avg       0.75      0.67      0.65       100\n","              precision    recall  f1-score   support\n","\n","           0       0.82      0.91      0.86        64\n","           1       0.79      0.64      0.71        36\n","\n","    accuracy                           0.81       100\n","   macro avg       0.81      0.77      0.78       100\n","weighted avg       0.81      0.81      0.80       100\n","\n","weighted avg       0.81      0.81      0.80       100\n","              precision    recall  f1-score   support\n","\n","           0       0.38      0.79      0.51        34\n","           1       0.76      0.33      0.46        66\n","\n","    accuracy                           0.49       100\n","   macro avg       0.57      0.56      0.49       100\n","weighted avg       0.63      0.49      0.48       100\n","\n","weighted avg       0.63      0.49      0.48       100\n","              precision    recall  f1-score   support\n","\n","           0       0.66      0.92      0.77        61\n","           1       0.67      0.26      0.37        39\n","\n","    accuracy                           0.66       100\n","   macro avg       0.66      0.59      0.57       100\n","weighted avg       0.66      0.66      0.61       100\n","\n","weighted avg       0.66      0.66      0.61       100\n","Precision:0.75\n","Recall:0.67\n","Score0.7216626506024095\n","Precision:0.81\n","Recall:0.81\n","Score0.81\n","Precision:0.63\n","Recall:0.49\n","Score0.5758895705521472\n","Precision:0.66\n","Recall:0.66\n","Score0.66\n","0.6918880552886393\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n","dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='13' max='813' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [ 13/813 00:16 < 20:20, 0.66 it/s, Epoch 0.01/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>10</td>\n","      <td>0.223900</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}}]}]}